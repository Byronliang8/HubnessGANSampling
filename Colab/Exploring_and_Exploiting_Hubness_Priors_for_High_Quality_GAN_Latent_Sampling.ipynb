{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploring and Exploiting Hubness Priors for High-Quality GAN Latent Sampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6QrjF9v//7UOkFOQcecGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byronliang8/HubnessGANSampling/blob/main/Colab/Exploring_and_Exploiting_Hubness_Priors_for_High_Quality_GAN_Latent_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hubness Priors\n",
        "This code is to show how to generate the high-quality images by using hubness priors. You also can test the code into the other different model by compute the GAN latent codes. Our code is based on the StyleGAN2 Paper: https://arxiv.org/abs/1812.04948 and Code: https://nvlabs.github.io/stylegan2/versions.html.\n",
        "\n"
      ],
      "metadata": {
        "id": "qTwnRIMN4ZtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObLo_yVd4SAO"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-hubness\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "%cd stylegan2-ada-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model of choice\n",
        "import PIL.Image\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import os\n",
        "import re\n",
        "from typing import List, Optional\n",
        "\n",
        "import click\n",
        "import dnnlib\n",
        "\n",
        "import PIL.Image\n",
        "import torch\n",
        "\n",
        "import legacy\n",
        "\n",
        "from io import BytesIO, StringIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "from skhubness.neighbors import NearestNeighbors\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import dill as pickle\n",
        "\n",
        "# Choose between these pretrained models - I think 'f' is the best choice:\n",
        "\n",
        "\n",
        "network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "\n",
        "# If downloads fails, due to 'Google Drive download quota exceeded' you can try downloading manually from your own Google Drive account\n",
        "# network_pkl = \"/content/drive/My Drive/GAN/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "device = torch.device('cuda')\n",
        "with dnnlib.util.open_url(network_pkl) as f:\n",
        "  G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "#noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbdE1RYR5VJc",
        "outputId": "1e9ebb39-e207-4001-a371-8584e4e49997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The functions"
      ],
      "metadata": {
        "id": "pNzXmZEz5v_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcation\n",
        "def generate_list_latent(recorder_list, dls):\n",
        "    out = []\n",
        "    for i in recorder_list:\n",
        "        out.append(dls[i])\n",
        "    out=torch.stack(out)\n",
        "    return out\n",
        "\n",
        "def generate_images(zs):\n",
        "    imgs=[]\n",
        "    for i in zs:\n",
        "        latent=i.reshape(1,len(i))\n",
        "        img=G(latent,c)\n",
        "        img =(img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "        imgs.append(PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_images_inW(w):\n",
        "    imgs=[]\n",
        "    for i in w:\n",
        "        latent=i.reshape(1,len(i),len(i[0]))\n",
        "        img = G.synthesis(latent, noise_mode='const', force_fp32=True)\n",
        "        img =(img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "        imgs.append(PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def imshow(imgs_list,format='png', jpeg_fallback=True):\n",
        "    imgs_list = np.asarray(imgs_list, dtype=np.uint8)\n",
        "    str_file = BytesIO()\n",
        "    PIL.Image.fromarray(imgs_list).save(str_file, format)\n",
        "    im_data = str_file.getvalue()\n",
        "    try:\n",
        "        disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "    except IOError:\n",
        "        if jpeg_fallback and format != 'jpeg':\n",
        "            print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "            return imshow(imgs_list, format='jpeg')\n",
        "        else:\n",
        "            raise\n",
        "    return disp\n",
        "\n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols)))\n",
        "   return canvas\n",
        "\n",
        "def getRecorder(value,s,threshold):\n",
        "    recorder = []\n",
        "    for i in range(s):\n",
        "        if value[0][i] >=threshold:\n",
        "            #if value[0][i]>=30:\n",
        "                recorder.append(i)\n",
        "                #print(value[0][i])\n",
        "    return recorder\n",
        "\n",
        "def getK_Occ(k,high_list):\n",
        "    neigh = NearestNeighbors(k)\n",
        "    # dls=np.asarray(dls)\n",
        "    neigh.fit(high_list)\n",
        "    theArray = neigh.kneighbors_graph(high_list)\n",
        "    #z-space\n",
        "    #dls=np.asarray(dls)\n",
        "    neigh.fit(high_list)\n",
        "    theArray = neigh.kneighbors_graph(high_list)\n",
        "\n",
        "    value = np.sum(theArray,axis=0)  # to compute the point was connected (if is 1, that is to compute the compute to connect-> always k)\n",
        "    value = np.asarray(value)\n",
        "    return value\n",
        "\n",
        "def to_torch(list):\n",
        "    return torch.tensor(list).cuda()\n",
        "\n",
        "def to_numpy(list):\n",
        "    out=[]\n",
        "    for i in list:\n",
        "        out.append(i.cpu().numpy())\n",
        "    return out\n",
        "\n",
        "def change_circle(hubs_code_w,index=0,step=0.01):\n",
        "    target_circle=hubs_code_w[index].clone()\n",
        "    latent_circle=[]\n",
        "    lenth=target_circle.shape\n",
        "    for i in range(lenth[1]-1):\n",
        "        target_circle=hubs_code_w[index].clone()\n",
        "        for j in range(lenth[0]-1):\n",
        "            target_circle[j][i]=target_circle[j][i]+step\n",
        "    #print(target_circle.shape)\n",
        "        latent_circle.append( target_circle)\n",
        "    return latent_circle\n",
        "\n",
        "def get_trunca(latent_list,threshold=0.7):\n",
        "    out=[]\n",
        "    latent_list=to_numpy(latent_list)\n",
        "    latent_mean=get_mean(latent_list)\n",
        "    for i in latent_list:\n",
        "        trun_i=latent_mean+(i-latent_mean)*threshold\n",
        "        out.append(trun_i)\n",
        "    out=to_torch(out)\n",
        "    return out\n",
        "\n",
        "def get_mean(latent_list):\n",
        "    #latent_list=latent_list.cpu().numpy()\n",
        "    out=np.mean(latent_list, axis=0)\n",
        "    return out\n",
        "\n",
        "def get_distance(latent_list,avr):\n",
        "    out=[]\n",
        "    for i in latent_list:\n",
        "        if len(i.shape)==2:\n",
        "            dst = distance.euclidean(i[0],avr[0])\n",
        "            out.append(dst)\n",
        "        elif len(i.shape)<2:\n",
        "            dst = distance.euclidean(i,avr)\n",
        "            out.append(dst)\n",
        "    return out\n",
        "\n",
        "def edit_step(input,edit_vectors,size=10,step=-0.4):\n",
        "    edit=[]\n",
        "    for i in range(size):\n",
        "        edit_latent=input+edit_vectors*(i)*step\n",
        "        edit.append(edit_latent)\n",
        "\n",
        "    edit=torch.tensor(edit).cuda()\n",
        "    edit=edit.reshape(size,18,512)\n",
        "    return edit\n",
        "\n",
        "def affine_different_from_editing(ws,ws_smile):\n",
        "    bloc_list=[G.synthesis.b4,G.synthesis.b8,G.synthesis.b16,G.synthesis.b32,G.synthesis.b64,G.synthesis.b128,G.synthesis.b256,G.synthesis.b512,G.synthesis.b1024]\n",
        "    x_ws=img_ws=x_smile=img_smile=None\n",
        "    diffs=[]\n",
        "    #w_iter = iter(ws.unbind(dim=1))\n",
        "    for i in bloc_list:\n",
        "        input_size=i.num_torgb+i.num_conv\n",
        "    # initial images\n",
        "        x_ws,img_ws=i(x_ws,img_ws,ws[0][0:input_size].reshape(1,input_size,512))\n",
        "    # get the affine (the input for synthesis layer)\n",
        "        affine_ws = i.conv1.affine(ws[0][0].reshape(1,512))\n",
        "        #if i.in_channels == 0:\n",
        "        #   affine_ws = i.conv1.affine(ws[0][0].reshape(1,512))\n",
        "        #elif i.architecture == 'resnet':\n",
        "        #   affine_ws = i.conv1.affine(ws[0][0].reshape(1,512))\n",
        "\n",
        "    #smile images\n",
        "        x_smile,img_smile=i(x_smile,img_smile,ws_smile[0][0:input_size].reshape(1,input_size,512))\n",
        "    # get the affine (the input for synthesis layer)\n",
        "        affine_smile = i.conv1.affine(ws_smile[0][0].reshape(1,512))\n",
        "        #if i.in_channels == 0:\n",
        "        #    affine_smile = i.conv1.affine(ws_smile[0][0].reshape(1,512))\n",
        "        #elif i.architecture == 'resnet':\n",
        "        #    affine_smile = i.conv1.affine(ws_smile[0][0].reshape(1,512))\n",
        "\n",
        "    # compute the affine different for the style layer\n",
        "        diff_=affine_ws-affine_smile\n",
        "        diff_=to_numpy(diff_)\n",
        "        diffs.append(diff_)\n",
        "    return diffs\n",
        "\n",
        "def get_styles(affine):\n",
        "    styles=affine\n",
        "    return styles / styles.norm(float('inf'), dim=1, keepdim=True)\n",
        "\n",
        "def style_layer_w_out(affines):\n",
        "    styles=[]\n",
        "    for j,i in enumerate(affines):\n",
        "        styles.append(get_styles(i))\n",
        "    return styles\n",
        "\n",
        "def affine_w_out(ws):\n",
        "    bloc_list=[G.synthesis.b4,G.synthesis.b8,G.synthesis.b16,G.synthesis.b32,G.synthesis.b64,G.synthesis.b128,G.synthesis.b256,G.synthesis.b512,G.synthesis.b1024]\n",
        "    affines=[]\n",
        "    w_iter = iter(ws.unbind(dim=1))\n",
        "    for j,i in enumerate(bloc_list):\n",
        "        affine_ws1 = i.conv1.affine(next(w_iter))\n",
        "        affines.append(affine_ws1)\n",
        "        #affine_rgb = i.torgb.affine(next(w_iter))\n",
        "        #affines.append(affine_rgb)\n",
        "        if j >0:\n",
        "            affine_ws0 = i.conv0.affine(next(w_iter))\n",
        "            affines.append(affine_ws0)\n",
        "    return affines\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def feature_map_analyze(ws):\n",
        "    bloc_list=[G.synthesis.b4,G.synthesis.b8,G.synthesis.b16,G.synthesis.b32,G.synthesis.b64,G.synthesis.b128,G.synthesis.b256,G.synthesis.b512,G.synthesis.b1024]\n",
        "    xs=[]\n",
        "    imgs=[]\n",
        "    x=img=None\n",
        "    w_idx=0\n",
        "    for i in (bloc_list):\n",
        "        input_size=i.num_torgb+i.num_conv\n",
        "        input_w=ws.narrow(1, w_idx,input_size )#size=i.num_conv + i.num_torgb\n",
        "        x,img=i(x,img,input_w)\n",
        "        xs.append(x)\n",
        "        imgs.append(img)\n",
        "        w_idx += i.num_conv\n",
        "    return xs,imgs\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )"
      ],
      "metadata": {
        "id": "Pt1PHtE05qLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3FEIcnK351mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The random generation"
      ],
      "metadata": {
        "id": "d_vTZ-cu6NQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(G)"
      ],
      "metadata": {
        "id": "YXJvgi9Uhxwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=25\n",
        "zs = torch.randn([s, G.z_dim]).cuda()    # latent codes\n",
        "c = None\n",
        "\n",
        "w = G.mapping(zs, c, truncation_psi=1, truncation_cutoff=8)\n",
        "imgs=generate_images_inW(w)\n",
        "#saveImgs(imgs,'Random/')\n",
        "imshow(createImageGrid(imgs[0:25],0.4,5))"
      ],
      "metadata": {
        "id": "9Uumz3v65329"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The hubness priors "
      ],
      "metadata": {
        "id": "AB3RgNNH6chh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s=10000\n",
        "k=5\n",
        "zs = torch.randn([s, G.z_dim]).cuda()    # latent codes\n",
        "c = None\n",
        "w = G.mapping(zs, c, truncation_psi=1, truncation_cutoff=8)\n",
        "\n",
        "w_np=to_numpy(w)\n",
        "w_input=[]\n",
        "for j in w_np:\n",
        "    w_input.append(j[0])\n",
        "\n",
        "value_w=getK_Occ(k,w_input)# get hub value\n",
        "    #print('done')\n",
        "\n",
        "# hubness priors\n",
        "threshold=50\n",
        "recorder_w=getRecorder(value_w,s,threshold)\n",
        "hubs_code_w = generate_list_latent(recorder_w, w)# t hub latents\n",
        "print(hubs_code_w.shape)\n",
        "\n",
        "hubs_imgs=generate_images_inW(hubs_code_w)\n",
        "#dir='hubsimage/hubs_'\n",
        "#saveImgs(hubs_imgs,dir)\n",
        "imshow(createImageGrid(hubs_imgs[0:25],0.4,5))"
      ],
      "metadata": {
        "id": "le8E7hpf6g_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}